{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biol 359A  | Descriptive statistics and comparing groups\n",
    "### Spring 2022, Week 2\n",
    "<hr>\n",
    "\n",
    "Objectives:\n",
    "-  Read basic python syntax\n",
    "-  Run and interpret a t-test\n",
    "-  Gain intuition about statistical tests and sample sizes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of bash commands to make google colab work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr22/week2_statisticaltests\n",
    "!mkdir ./data\n",
    "!cp week2_statisticaltests/data/* ./data\n",
    "!cp week2_statisticaltests/clean_data.py ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements\n",
    "\n",
    "Import statements are used to integrate *external code or packages* into our analysis. \n",
    "\n",
    "- `pandas`: Represents data as tables\n",
    "- `seaborn`: Data exploration visualization tool\n",
    "- `ipywidgets`: Notebook widgets that add user interfaces to notebooks\n",
    "- `random`: Generate random numbers\n",
    "- `numpy`: General math/matrices package\n",
    "- `matplotlib`: Data visualization software\n",
    "- `Scipy`: General scientific computing\n",
    "\n",
    "Using `as` will alias the package in the code.\n",
    "`matplotlib.pyplot` is importing the submodule `pyplot` from `matplotlib`. \n",
    "`from scipy.stats` is telling python where to find `ttest_ind`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind as ttest\n",
    "\n",
    "TITLE_FONT = 20\n",
    "LABEL_FONT = 16\n",
    "TICK_FONT = 16\n",
    "FIG_SIZE = (15,15)\n",
    "COLORS= [\"#008080\",\"#CA562C\"]\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common data visualizations\n",
    "\n",
    "First we are going to create a toy dataset using a random number generator. \n",
    "Here we use the Normal distribution function (pdf):\n",
    "\n",
    "\n",
    "$$\n",
    "  f_X(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \n",
    "  \\exp\\left( -\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_normal_distribution(n = 100, mu = 6, sigma = 2):\n",
    "    return [random.gauss(mu, sigma) for _ in range(0,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77c09355ad34ba1b6b5cbbf1c95e917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='n', max=1000, min=3), IntSlider(value=6, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_a_histogram(x, n, mu, sigma):\n",
    "    \"\"\"Generate annotated histogram based on normal (gaussian) distribution\"\"\"\n",
    "    data_color = COLORS[0]\n",
    "    annotation_color= COLORS[1]\n",
    "    plt.figure(figsize=FIG_SIZE)\n",
    "    sns.histplot(x, color=data_color, kde=True, stat=\"probability\")\n",
    "    _, xmax, _, ymax = plt.axis()\n",
    "    plt.title(\"Histogram of random values generated from a normal distribution\", fontsize=TITLE_FONT)\n",
    "    \n",
    "    plt.axvline(mu, linestyle='--', color=annotation_color, lw=3)\n",
    "    plt.text(mu, .97*ymax, r' $\\mu$', color=annotation_color, fontsize=LABEL_FONT, ma=\"left\")\n",
    "    \n",
    "    plt.axvline(mu+sigma, linestyle=':',color=annotation_color, lw=3)\n",
    "    plt.text(mu+sigma, .97*ymax, r' $\\mu+\\sigma$', color=annotation_color, fontsize=LABEL_FONT, ma=\"left\")\n",
    "\n",
    "    plt.axvline(mu-sigma, linestyle=':',color=annotation_color, lw=3)\n",
    "    plt.text(mu-sigma, .97*ymax, r' $\\mu-\\sigma$', color=annotation_color, fontsize=LABEL_FONT, ma=\"right\")\n",
    "    \n",
    "    plt.text(.8*xmax, .9*ymax, 'Data', color=data_color, fontsize=LABEL_FONT, weight=\"bold\")\n",
    "    plt.text(.8*xmax, .93*ymax, 'Underlying distribution', color=annotation_color, fontsize=LABEL_FONT, weight=\"bold\")\n",
    "    \n",
    "    sns.despine()\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "@widgets.interact_manual(n=(3,1000), mu=(-10, 10), sigma=(0,10))\n",
    "def create_histplot(n=100, mu=6, sigma=2): \n",
    "    toy_dataset_x = generate_normal_distribution(n=n, mu=mu, sigma=sigma)\n",
    "    plot_a_histogram(toy_dataset_x, n, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Histograms__ use discrete bins (range of values) to categorize data, and are used primarily to visualize probability or proportions. Most visualizations of probability are based on histogram-like structures, and the kernel density estimate (KDE) line is the best guess at an underlying distribution. The higher the bar in a bin, the more times a value occurs in that bin within a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f6aa8515654022b28b119a79db5fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='n', max=1000, min=3), IntSlider(value=6, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_a_boxplot(x, n, mu, sigma, swarm):\n",
    "    \"\"\"Generate annotated boxplot based on normal (gaussian) distribution\"\"\"\n",
    "    data_color = COLORS[0]\n",
    "    annotation_color= COLORS[1]\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.boxplot(data=x, color=data_color,orient='h', boxprops=dict(alpha=.5), showmeans=True,\n",
    "                meanprops={\"marker\":\"o\",\n",
    "                           \"markerfacecolor\":\"white\", \n",
    "                           \"markeredgecolor\":\"black\",\n",
    "                           \"markersize\":\"6\"})\n",
    "    if swarm: sns.stripplot(data=x, orient='h',size=5, color=\".3\", linewidth=0)\n",
    "    \n",
    "    _, xmax, _, ymax = plt.axis()\n",
    "    plt.title(\"Boxplot of random values generated from a normal distribution\", fontsize=TITLE_FONT)\n",
    "    \n",
    "    plt.axvline(mu, linestyle='--', color=annotation_color, lw=3)\n",
    "    plt.text(mu, -0.9*ymax, r' $\\mu$', color=annotation_color, fontsize=LABEL_FONT, ma=\"left\")\n",
    "    \n",
    "    plt.axvline(mu+sigma, linestyle=':',color=annotation_color, lw=3)\n",
    "    plt.text(mu+sigma, -0.9*ymax, r' $\\mu+\\sigma$', color=annotation_color, fontsize=LABEL_FONT, ma=\"left\")\n",
    "\n",
    "    plt.axvline(mu-sigma, linestyle=':',color=annotation_color, lw=3)\n",
    "    plt.text(mu-sigma, -0.9*ymax, r' $\\mu-\\sigma$', color=annotation_color, fontsize=LABEL_FONT, ma=\"right\")\n",
    "    \n",
    "    plt.text(0.75*xmax, 0.6*ymax, 'Data', color=data_color, fontsize=LABEL_FONT, weight=\"bold\")\n",
    "    plt.text(0.75*xmax, 0.8*ymax, 'Underlying distribution', color=annotation_color, fontsize=LABEL_FONT, weight=\"bold\")\n",
    "    sns.despine()\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "@widgets.interact_manual(n=(3,1000), mu=(-10, 10), sigma=(0,10))\n",
    "def create_boxplot(n=100, mu=6, sigma=2, swarm=True): \n",
    "    toy_dataset_x = generate_normal_distribution(n=n, mu=mu, sigma=sigma)\n",
    "    plot_a_boxplot(toy_dataset_x, n, mu, sigma, swarm=swarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Box plots__ are common for comparing data, which we will be using later. The _box_ represents the interquartile range, or the data that contains the middle 50 percent of the data. The _whiskers_ represent the range of the distribution, adjusted for outliers, represented by _diamonds_. The _circle_ represents the sample mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4571c755ab7c40f8b440e175baaafc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='n', max=1000, min=3), IntSlider(value=6, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_a_scatterplot(x, y, n, mu_x, sigma_x, mu_y, sigma_y):\n",
    "    \"\"\"Generate annotated boxplot based on normal (gaussian) distribution\"\"\"\n",
    "    data_color = COLORS[0]\n",
    "    annotation_color= COLORS[1]\n",
    "    sns.jointplot(x=x, \n",
    "                  y=y,\n",
    "                  kind=\"reg\",color=data_color,\n",
    "                  marginal_kws=dict(bins=10,color=annotation_color));\n",
    "    plt.xlabel(r\"X data $\\mu={0}$,$\\sigma={1}$\".format(mu_x,sigma_x))\n",
    "    plt.ylabel(r\"Y data $\\mu={0}$,$\\sigma={1}$\".format(mu_y,sigma_y))\n",
    "\n",
    "    sns.despine()\n",
    "    plt.show()  \n",
    "    \n",
    "@widgets.interact_manual(n=(3,1000), mu_x=(-10, 10), sigma_x=(0,10), mu_y=(-10, 10), sigma_y=(0,10))\n",
    "def create_scatterplot(n=100, mu_x=6, sigma_x=2, mu_y=6, sigma_y=2): \n",
    "    toy_dataset_x = generate_normal_distribution(n=n, mu=mu_x, sigma=sigma_x)\n",
    "    toy_dataset_y = generate_normal_distribution(n=n, mu=mu_y, sigma=sigma_y)\n",
    "    plot_a_scatterplot(toy_dataset_x, toy_dataset_y, n, mu_x, sigma_x, mu_y, sigma_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Scatter plots__ are designed to show *pairs* of data points. Each X-axis data point is associated with a Y-axis data point. These plots will be common when we're talking about associations between continuous variables, specifically for discussions of correlation (and regression - you can ignore the line through the points for now). The histograms have been included to help associate the data sets to the scatter points. Remember, these data were randomly generated and paired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition: Central limit theorem\n",
    "\n",
    "You can ignore the code below! It is setting up an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_datasets(n, rng, repetitions=200):\n",
    "    averages = []\n",
    "    all_nums = []\n",
    "    for i in range(0, repetitions):\n",
    "        nums = [generate_random_numbers(rng) for _ in range(0,n)]\n",
    "        all_nums += nums\n",
    "        averages.append(np.mean(nums))\n",
    "    return all_nums, averages\n",
    "    \n",
    "def generate_histograms_clt(axs, n=10, rng=\"uniform\"):\n",
    "    \"\"\"build 2x2 matrix of histograms\"\"\"\n",
    "\n",
    "    all_nums_fixed, averages_fixed = get_random_datasets(10, rng)\n",
    "    build_paired_histograms(averages_fixed, all_nums_fixed, 10, rng, axs, column=0)\n",
    "    \n",
    "    all_nums, averages = get_random_datasets(n, rng)\n",
    "    build_paired_histograms(averages, all_nums, n, rng, axs, column=1)\n",
    "    \n",
    "def build_paired_histograms(averages, all_nums, n, rng, axs, column):\n",
    "    colors=[\"#1e81b0\", \"#e28743\"]\n",
    "    color = colors[column]\n",
    "    axs[0,column].set_title(f\"random samples\")\n",
    "    axs[1,column].set_title(f\"sample averages\")\n",
    "    axs[0,column].text(0.9, 0.9, f\"n:{n}\"+r\" $\\mu$: {0:.2f}, $\\sigma$:{1:.2f}\".format(np.mean(all_nums), np.std(all_nums)) ,\n",
    "                       verticalalignment='bottom', horizontalalignment='right',\n",
    "                       transform=axs[0,column].transAxes,\n",
    "                       color=color, fontsize=LABEL_FONT)\n",
    "    axs[1,column].text(0.9, 0.9, f\"n:{n}\"+r\" $\\mu$: {0:.2f}, $\\sigma$:{1:.2f}\".format(np.mean(averages), np.std(averages)),\n",
    "                       verticalalignment='bottom', horizontalalignment='right',\n",
    "                       transform=axs[1,column].transAxes,\n",
    "                       color=color, fontsize=LABEL_FONT)\n",
    "    sns.histplot(all_nums, ax=axs[0, column], color = color, stat=\"probability\", kde=True)\n",
    "    sns.histplot(averages, bins=10, ax=axs[1, column], color = color, stat=\"probability\", kde=True)\n",
    "    axs[1, column].set_xlim(0,10)\n",
    "    \n",
    "    \n",
    "def generate_random_numbers(generator = \"uniform\"):\n",
    "    \"\"\"generate random numbers with a mean of 5\"\"\"\n",
    "    if generator == \"uniform\": return random.uniform(0,10)\n",
    "    elif generator == \"exponential\": return random.expovariate(1/5)\n",
    "    elif generator == \"normal\": return random.gauss(5,2)\n",
    "    \n",
    "def format_plots(axs):\n",
    "    for ax in axs.flat:\n",
    "        title = ax.get_title()\n",
    "        ax.set_title(title, fontweight=\"bold\", size=LABEL_FONT)\n",
    "        ax.set_ylabel('Proportion (Probability)', fontsize = LABEL_FONT)\n",
    "        ax.set_xlabel('Number', fontsize = LABEL_FONT)\n",
    "        ax.tick_params(labelsize=TICK_FONT)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The central limit theorem \n",
    "\n",
    "Here we a couple of plots for you to interact with. The left-side plots are fixed to collecting 10 samples from the distribution. The top row of plots shows the histograms of the underlying data points (here n samples x 200 repititions) and the bottom row shows the distribution of averages (200 repititions). Are the results what you would expect from the central limit theorem (CLT)? Does it hold true for other distributions? Is there a distribution shown here that the CLT does not hold true for? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64f0568618343e08f0d171a310225d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='n', min=3), Dropdown(description='generator', index=1, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact_manual(n=(3,100),  generator=[\"uniform\",\"exponential\",\"normal\"])\n",
    "def demonstrate_clt(n=10, generator=\"exponential\"):\n",
    "    random.seed(10)\n",
    "    fig, axs = plt.subplots(2, 2, figsize=FIG_SIZE, constrained_layout=True)\n",
    "    fig.suptitle(f\"Random number generator (distribution): {generator}\",fontweight=\"bold\", size=TITLE_FONT)\n",
    "    generate_histograms_clt(axs, n, generator)\n",
    "    format_plots(axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding our data\n",
    "\n",
    "We are going to import a dataset using another python script. The python script is loading the file and doing some basic cleaning of parts of the dataset we aren't using. It can be found in `clean_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>842302</th>\n",
       "      <th>M</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842517</th>\n",
       "      <th>M</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84300903</th>\n",
       "      <th>M</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84348301</th>\n",
       "      <th>M</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84358402</th>\n",
       "      <th>M</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926424</th>\n",
       "      <th>M</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926682</th>\n",
       "      <th>M</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926954</th>\n",
       "      <th>M</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927241</th>\n",
       "      <th>M</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92751</th>\n",
       "      <th>B</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean_radius  mean_texture  mean_perimeter  mean_area  \\\n",
       "ID       diagnosis                                                         \n",
       "842302   M                17.99         10.38          122.80     1001.0   \n",
       "842517   M                20.57         17.77          132.90     1326.0   \n",
       "84300903 M                19.69         21.25          130.00     1203.0   \n",
       "84348301 M                11.42         20.38           77.58      386.1   \n",
       "84358402 M                20.29         14.34          135.10     1297.0   \n",
       "...                         ...           ...             ...        ...   \n",
       "926424   M                21.56         22.39          142.00     1479.0   \n",
       "926682   M                20.13         28.25          131.20     1261.0   \n",
       "926954   M                16.60         28.08          108.30      858.1   \n",
       "927241   M                20.60         29.33          140.10     1265.0   \n",
       "92751    B                 7.76         24.54           47.92      181.0   \n",
       "\n",
       "                    mean_smoothness  mean_compactness  mean_concavity  \\\n",
       "ID       diagnosis                                                      \n",
       "842302   M                  0.11840           0.27760         0.30010   \n",
       "842517   M                  0.08474           0.07864         0.08690   \n",
       "84300903 M                  0.10960           0.15990         0.19740   \n",
       "84348301 M                  0.14250           0.28390         0.24140   \n",
       "84358402 M                  0.10030           0.13280         0.19800   \n",
       "...                             ...               ...             ...   \n",
       "926424   M                  0.11100           0.11590         0.24390   \n",
       "926682   M                  0.09780           0.10340         0.14400   \n",
       "926954   M                  0.08455           0.10230         0.09251   \n",
       "927241   M                  0.11780           0.27700         0.35140   \n",
       "92751    B                  0.05263           0.04362         0.00000   \n",
       "\n",
       "                    mean_concave_points  mean_symmetry  mean_fractal_dimension  \n",
       "ID       diagnosis                                                              \n",
       "842302   M                      0.14710         0.2419                 0.07871  \n",
       "842517   M                      0.07017         0.1812                 0.05667  \n",
       "84300903 M                      0.12790         0.2069                 0.05999  \n",
       "84348301 M                      0.10520         0.2597                 0.09744  \n",
       "84358402 M                      0.10430         0.1809                 0.05883  \n",
       "...                                 ...            ...                     ...  \n",
       "926424   M                      0.13890         0.1726                 0.05623  \n",
       "926682   M                      0.09791         0.1752                 0.05533  \n",
       "926954   M                      0.05302         0.1590                 0.05648  \n",
       "927241   M                      0.15200         0.2397                 0.07016  \n",
       "92751    B                      0.00000         0.1587                 0.05884  \n",
       "\n",
       "[569 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clean_data #helper function with \n",
    "\n",
    "cancer_dataset = clean_data.generate_clean_dataframe()\n",
    "cancer_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a basic understanding of the structure of the data now. \n",
    "\n",
    "From the data source: Wisconsin Diagnostic Breast Cancer (WDBC)\n",
    "\n",
    "```\n",
    "\tFeatures are computed from a digitized image of a fine needle\n",
    "\taspirate (FNA) of a breast mass.  They describe\n",
    "\tcharacteristics of the cell nuclei present in the image.\n",
    "\tA few of the images can be found at\n",
    "\thttp://www.cs.wisc.edu/~street/images/\n",
    "\n",
    "\tSeparating plane described above was obtained using\n",
    "\tMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
    "\tConstruction Via Linear Programming.\" Proceedings of the 4th\n",
    "\tMidwest Artificial Intelligence and Cognitive Science Society,\n",
    "\tpp. 97-101, 1992], a classification method which uses linear\n",
    "\tprogramming to construct a decision tree.  Relevant features\n",
    "\twere selected using an exhaustive search in the space of 1-4\n",
    "\tfeatures and 1-3 separating planes.\n",
    "\n",
    "\tThe actual linear program used to obtain the separating plane\n",
    "\tin the 3-dimensional space is that described in:\n",
    "\t[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
    "\tProgramming Discrimination of Two Linearly Inseparable Sets\",\n",
    "\tOptimization Methods and Software 1, 1992, 23-34].\n",
    "    \n",
    "    Source:\n",
    "    W.N. Street, W.H. Wolberg and O.L. Mangasarian \n",
    "\tNuclear feature extraction for breast tumor diagnosis.\n",
    "\tIS&T/SPIE 1993 International Symposium on Electronic Imaging: Science\n",
    "\tand Technology, volume 1905, pages 861-870, San Jose, CA, 1993.\n",
    "```\n",
    "\n",
    "What do all the column names mean?\n",
    "\n",
    "- ID number\n",
    "- Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry \n",
    "- fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "\n",
    "Cateogory Distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to show the first five values in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID        diagnosis\n",
       "842302    M            1001.0\n",
       "842517    M            1326.0\n",
       "84300903  M            1203.0\n",
       "84348301  M             386.1\n",
       "84358402  M            1297.0\n",
       "Name: mean_area, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_dataset[\"mean_area\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to show the first five values from the groups in the diagnosis column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID        diagnosis\n",
       "842302    M            1001.0\n",
       "842517    M            1326.0\n",
       "84300903  M            1203.0\n",
       "84348301  M             386.1\n",
       "84358402  M            1297.0\n",
       "8510426   B             566.3\n",
       "8510653   B             520.0\n",
       "8510824   B             273.9\n",
       "854941    B             523.8\n",
       "85713702  B             201.9\n",
       "Name: mean_area, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_dataset[\"mean_area\"].groupby(\"diagnosis\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to calculate basic descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count =  569\n",
      "mean =  654.89\n",
      "var =  123625.90\n",
      "std =  351.60\n"
     ]
    }
   ],
   "source": [
    "def calculate_count(x):\n",
    "    return len(x)\n",
    "\n",
    "def calculate_mean(x):\n",
    "    return np.sum(x) / len(x)\n",
    "\n",
    "def calculate_variance(x):\n",
    "    return calculate_mean((x - calculate_mean(x))**2)\n",
    "\n",
    "def calculate_std(x):\n",
    "    return np.sqrt(calculate_variance(x))\n",
    "\n",
    "area = cancer_dataset[\"mean_area\"]\n",
    "\n",
    "print(f\"count =  {calculate_count(area):.0f}\")\n",
    "print(f\"mean =  {calculate_mean(area):.2f}\")\n",
    "print(f\"var =  {calculate_variance(area):.2f}\")\n",
    "print(f\"std =  {calculate_std(area):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` has us covered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     569.000000\n",
       "mean      654.889104\n",
       "std       351.914129\n",
       "min       143.500000\n",
       "25%       420.300000\n",
       "50%       551.100000\n",
       "75%       782.700000\n",
       "max      2501.000000\n",
       "Name: mean_area, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_dataset[\"mean_area\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a difference? The standard deviation is being calculated differently. Simply taking the square root of the variance doesn't give you an unbiased estimator. What is the main difference between the estimate in `calculate_std_est()` and the previous one in `calculate_std()`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculate_std_est' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bf732782c7e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcalculate_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"unbiased std =  {calculate_std_est(area):.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'calculate_std_est' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_unbiased_std(x):\n",
    "    \"\"\"unbiased estimator\"\"\"\n",
    "    return np.sqrt(np.sum((x - calculate_mean(x))**2)/(len(x)-1))\n",
    "\n",
    "print(f\"unbiased std =  {calculate_std_est(area):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing variables\n",
    "\n",
    "What if we're interested in the relationship between variables? Here we calculate the Pearson correlation coefficient $\\rho$. Which variables appear correlated? Which don't appear correlated? Is there a variable that appears correlated but likely not informative? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d800e3fbf494aab9b5a7fe11c10e094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='x', options=('mean_radius', 'mean_texture', 'mean_perimeter', 'mea…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create scatter plots of the various features\n",
    "def calculate_correlation(x,y):\n",
    "    return calculate_mean((x - calculate_mean(x)).transpose() * (y - calculate_mean(y))) / np.sqrt(calculate_variance(x) * calculate_variance(y))\n",
    "    \n",
    "@widgets.interact(x=list(cancer_dataset), y=list(cancer_dataset))    \n",
    "def make_scatterplot(x=\"mean_radius\",y=\"mean_area\"):\n",
    "    colors=[\"#e28743\", \"#1e81b0\"]\n",
    "\n",
    "    corr = calculate_correlation(cancer_dataset[x], cancer_dataset[y])\n",
    "    index = int(corr > 0.5)\n",
    "    color = colors[index]\n",
    "    plt.title(r\"correlation: $\\rho = ${:.3f}\".format(corr), color= color, size=TITLE_FONT)\n",
    "    sns.scatterplot(data=cancer_dataset, x=x, y=y, alpha=0.5, color=color);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's split the variables up by their category (also called it's label in data science).\n",
    "\n",
    "Based on our available data, we're not that interested in what the descriptive statistics are on the individual columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d05ce22b724b728417a608910b43fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='variable', options=('mean_radius', 'mean_texture', 'mean_perimeter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_diagnoses_by_variable(variable: str, dataframe: pd.DataFrame = cancer_dataset):\n",
    "    \"\"\"Accepts column name to generate basic descriptions\"\"\"\n",
    "    df = dataframe.reset_index()\n",
    "    sns.boxplot(data=df, x=variable, y=df[\"diagnosis\"])\n",
    "    return dataframe[variable].groupby(\"diagnosis\").describe()\n",
    "\n",
    "@widgets.interact(variable=list(cancer_dataset))\n",
    "def comparison_wrapper(variable=\"mean_radius\"):\n",
    "    return compare_diagnoses_by_variable(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run a two-sample t-test on these categories\n",
    "\n",
    "The t-test we learned in class focused on comparing our sample to a known quantity. We often don't know that quantity, but we can compare it to another sample mean as the estimate for that quantity. For the motivated, visit https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html to see the documentation to see how to write the code for a t-test.\n",
    "\n",
    "This test requires us to assume that the variances from the two samples share a population variance. Practically, if your standard deviations between samples is small (think less than a ratio of 3), you should be okay. In practice, this means that a typical t-test is inappropriate for comparing from two different populations, but a Welch t-test with a slightly different test statistic (that is still from a t-distribution) is used: https://en.wikipedia.org/wiki/Welch%27s_t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ind_ttest(feature=\"mean_radius\", dataset = cancer_dataset, welch=False):\n",
    "    cat1 = dataset.xs(\"M\", level=1)\n",
    "    cat2 = dataset.xs(\"B\", level=1)\n",
    "    df = dataset.reset_index()\n",
    "    f, (ax_hist, ax_box) = plt.subplots(2, sharex=True)\n",
    "\n",
    "    sns.boxplot(data=df, x=feature, y=df[\"diagnosis\"], ax=ax_box)\n",
    "    sns.histplot(data=df, x=feature, hue=df[\"diagnosis\"], ax=ax_hist, stat=\"probability\", kde=True)\n",
    "    if welch: tstat, pvalue = ttest(cat1[feature], cat2[feature], equal_var=False)\n",
    "    else: tstat, pvalue = ttest(cat1[feature], cat2[feature])\n",
    "    print(f\"p-value: {pvalue:.2e}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use all the data points we have and compare malignant and benign tumors. Choose a variable and predict an outcome, you can then run a t-test to compare the means of the two groups. However, consider if the assumptions for a t-test are accurate (namely, do the variances come from the same sampling population)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7200c34c9a1342a2a4a7d16dfe7c235b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='variable', options=('mean_radius', 'mean_texture', 'mean_perimeter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(variable=list(cancer_dataset))\n",
    "def run_ttest(variable):\n",
    "    run_ind_ttest(feature=variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were there variables that you are uncomfortable making that assumption, based on the variance in the data? We can use a Welch's test that can account for that variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2aae17f325148d885eb64232b9f82c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='variable', options=('mean_radius', 'mean_texture', 'mean_perimeter…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact(variable=list(cancer_dataset))\n",
    "def run_welch_test(variable):\n",
    "    run_ind_ttest(feature=variable, welch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've compared the data based on all of the available data, but what if we were limited in the samples that we were able to collect? We will consider what happens to our comparisons and tests if we are only able to see a subsample of the available data. \n",
    "\n",
    "__Aside__: This process is similar to sampling from the empirical distribution function and is important for concepts like bootstrapping that you may encounter in further readings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7330cd9baf452fa6da7af1cd77bba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='feature', options=('mean_radius', 'mean_texture', 'mean_perimeter'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "@widgets.interact_manual(feature=list(cancer_dataset), n=(3,100))\n",
    "def run_sampled_ttest(feature=\"mean_radius\", n=3):\n",
    "    seed = 1\n",
    "    cat1 = cancer_dataset.xs(\"M\", level=1).sample(n, random_state=seed)\n",
    "    cat2 = cancer_dataset.xs(\"B\", level=1).sample(n)\n",
    "    \n",
    "    cat1[\"diagnosis\"] = \"M\"\n",
    "    cat2[\"diagnosis\"] = \"B\"\n",
    "    df = pd.concat([cat1,cat2]).reset_index()\n",
    "    f, (ax_hist, ax_box) = plt.subplots(2, sharex=True)\n",
    "\n",
    "    sns.boxplot(data=df, x=feature, y=df[\"diagnosis\"], ax=ax_box)\n",
    "    sns.histplot(data=df, x=feature, hue=df[\"diagnosis\"], ax=ax_hist, stat=\"probability\", kde=True)    \n",
    "    tstat, pvalue = ttest(cat1[feature], cat2[feature])\n",
    "    print(f\"p-value: {pvalue:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, if we are under the impression that the data does not share the population variance, we can use the Welch t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e5e9e8c6694c5ca8fd138bb21f7284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='feature', options=('mean_radius', 'mean_texture', 'mean_perimeter'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact_manual(feature=list(cancer_dataset), n=(3,100))\n",
    "def run_sampled_welch_ttest(feature=\"mean_radius\", n=3):\n",
    "    seed = 1\n",
    "    cat1 = cancer_dataset.xs(\"M\", level=1).sample(n, random_state=seed)\n",
    "    cat2 = cancer_dataset.xs(\"B\", level=1).sample(n)\n",
    "    \n",
    "    cat1[\"diagnosis\"] = \"M\"\n",
    "    cat2[\"diagnosis\"] = \"B\"\n",
    "    df = pd.concat([cat1,cat2]).reset_index()\n",
    "    f, (ax_hist, ax_box) = plt.subplots(2, sharex=True)\n",
    "\n",
    "    sns.boxplot(data=df, x=feature, y=df[\"diagnosis\"], ax=ax_box)\n",
    "    sns.histplot(data=df, x=feature, hue=df[\"diagnosis\"], ax=ax_hist, stat=\"probability\", kde=True)    \n",
    "    tstat, pvalue = ttest(cat1[feature], cat2[feature], equal_var=False)\n",
    "    print(f\"p-value: {pvalue:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test is a largely robust method of comparing the mean to a value or the mean of another group. The method is generally robust for skewed distributions. Here we are going to compare the t-distribution to the normal distribution. Keeping in mind the CLT, what can we say about the point of diminishing returns with the $t$-distribution? Is there a cutoff point for degrees of freedom? What does this say about our norm (There is no simple answer here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7487858130c547b7846ece79e84daa34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='df', min=3), Button(description='Run Interact', style=Bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import t, norm\n",
    "\n",
    "@widgets.interact_manual(df=(3,100))\n",
    "def t_vs_norm(df=3):\n",
    "    x = np.linspace(t.ppf(0.01, df), t.ppf(0.99, df), 100)\n",
    "    x = np.linspace(norm.ppf(0.01), norm.ppf(0.99), 100)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=FIG_SIZE)\n",
    "    ax.plot(x, t.pdf(x,df),'-', lw=5, alpha=0.6, label='t-distribution pdf')\n",
    "    ax.plot(x, norm.pdf(x),'k:', lw=5, alpha=0.6, label='normal distribution pdf')\n",
    "    plt.ylabel(\"Probability\", fontsize=LABEL_FONT)\n",
    "    plt.legend(loc=\"best\",fontsize=LABEL_FONT)\n",
    "    plt.xlabel(\"X\", fontsize=LABEL_FONT)\n",
    "    plt.title(r\"Student's $t$-Distribution vs. Normal Distribution\", fontsize=TITLE_FONT)\n",
    "    plt.ylim(0,.5)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
